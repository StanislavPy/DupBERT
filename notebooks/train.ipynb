{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import metrics as sk_metrics\n",
    "from catalyst.utils import set_global_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catalyst.dl import CriterionCallback, CheckpointCallback, AUCCallback\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from dupbert.model import DupBERT\n",
    "from dupbert.runner import TripletRunner\n",
    "from dupbert.dataset import TripletDataset\n",
    "\n",
    "from dupbert.dataset import TripletDataset\n",
    "from dupbert.config_reader import ConfigReader\n",
    "from dupbert.transforms import TextTokenizer, Encoder, PadSequencer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DupBERT example on quora data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = Path(os.getcwd()).parents[0]\n",
    "data_path = main_path / 'data'\n",
    "logs_path = main_path / 'logs'\n",
    "config_path = main_path / 'config/config.yaml'\n",
    "\n",
    "\n",
    "# Extract the parameters from config\n",
    "config = ConfigReader.load(\n",
    "    config_filepath=config_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path / 'train.csv')\n",
    "train_df = train_df.sample(n=100, random_state=123)\n",
    "\n",
    "train_df = train_df[['question1', 'question2', 'is_duplicate']].dropna(how='any')\n",
    "train_df['is_duplicate'] = train_df.is_duplicate.astype(float)\n",
    "\n",
    "train_X, valid_X = train_test_split(train_df, **config.train_test_split)\n",
    "\n",
    "train_triplets = train_X[['question1', 'question2', 'is_duplicate']].values\n",
    "valid_triplets = valid_X[['question1', 'question2', 'is_duplicate']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up parameters of experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make results reproducible\n",
    "set_global_seed(config.seed)\n",
    "\n",
    "# Model \n",
    "model = DupBERT(**config.model_params)\n",
    "\n",
    "# TripletRunner\n",
    "runner = TripletRunner()\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "        params=[{'params': model.parameters()}],\n",
    "         **config.optimizer\n",
    ")\n",
    "\n",
    "# Test Preprocessing stages\n",
    "encoder = Encoder(**config.encoder)\n",
    "pad_sequencer = PadSequencer(**config.pad_sequencer)\n",
    "txt_tokenizer = TextTokenizer(**config.txt_tokenizer)\n",
    "\n",
    "\n",
    "# Callbacks for calculating metrics per batch/epoch\n",
    "callbacks = [\n",
    "        AUCCallback(\n",
    "                input_key=model.keys.model_output,\n",
    "                 target_key=model.keys.targets\n",
    "        ),\n",
    "        CriterionCallback(\n",
    "                input_key=model.keys.model_output,\n",
    "                target_key=model.keys.targets,\n",
    "                metric_key=\"loss\"\n",
    "        ),\n",
    "        CheckpointCallback(\n",
    "                loader_key=\"valid\",\n",
    "                #  mode='runner',\n",
    "                 **config.early_stopping\n",
    "        ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TripletDataset(\n",
    "    train_triplets, txt_tokenizer,\n",
    "    encoder, pad_sequencer,\n",
    "    train_mode=True\n",
    ")\n",
    "valid_dataset = TripletDataset(\n",
    "    valid_triplets, txt_tokenizer,\n",
    "    encoder, pad_sequencer,\n",
    "    train_mode=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, **config.loaders)\n",
    "valid_loader = DataLoader(valid_dataset, **config.loaders)\n",
    "\n",
    "loaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"valid\": valid_loader,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    callbacks=callbacks,\n",
    "    verbose=True,\n",
    "    valid_loader='valid',\n",
    "    valid_metric='auc',\n",
    "    minimize_valid_metric=False,\n",
    "    **config.train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list()\n",
    "for prediction in runner.predict_loader(loader=valid_loader):\n",
    "    predictions.append(prediction[\"logits\"].detach().cpu().numpy())\n",
    "\n",
    "pred_probs = [_[0] for _ in chain(*predictions)]\n",
    "pred_class = [int(_ > .5) for _ in pred_probs]\n",
    "\n",
    "targets = valid_X['is_duplicate']\n",
    "\n",
    "metrics_df = pd.DataFrame(\n",
    "    sk_metrics.precision_recall_fscore_support(y_true=targets, y_pred=pred_class),\n",
    "    index=['precision', 'recall', 'f1', 'support']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
